{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-exception",
   "metadata": {},
   "source": [
    "# Gaussian Process Modeling of Light Curves\n",
    "\n",
    "In this notebook we exemplify the modeling of the light curves using a Gaussian process (GP).\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load the Original Dataset](#loadData)\n",
    "3. [Fit Gaussian Processes](#gps)\n",
    "    1. [Set Path to Save GP Files](#saveGps)\n",
    "    2. [Compute GP Fits](#makeGps)\n",
    "4. [Light Curve Visualization](#see)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import gps, sndata\n",
    "from utils.plasticc_pipeline import create_folder_structure, get_directories, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-exhaust",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-assembly",
   "metadata": {},
   "source": [
    "## 2. Load Dataset<a name=\"loadData\"></a>\n",
    "\n",
    "First, **write** the path to the folder that contains the dataset we want to use, `folder_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os_name = 'baseline_v2_0_paper'\n",
    "os_name = 'noroll_v2_0_paper'\n",
    "# os_name = 'presto_v2_0_paper'\n",
    "\n",
    "folder_path = f'/path/to/folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-rabbit",
   "metadata": {},
   "source": [
    "Then, **write** in `data_file_name` the name of the file where your dataset is saved.\n",
    "\n",
    "In this notebook we use the dataset saved in [2_preprocess_data](2_preprocess_data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_only_roll = 1\n",
    "is_updated = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra_name_to_save = 'ddf'\n",
    "extra_name_to_save = 'wfd'\n",
    "#extra_name_to_save = 'ddf_wfd'\n",
    "\n",
    "# name = 'train'\n",
    "name = 'test'\n",
    "\n",
    "# file_id = '000'\n",
    "file_id = '012' # until 012\n",
    "\n",
    "data_file_name = f'{name}_{extra_name_to_save}_{file_id}_gapless50.pckl'\n",
    "if is_only_roll:\n",
    "    data_file_name = f'{name}_{extra_name_to_save}_{file_id}_roll_gapless50.pckl'\n",
    "if is_updated:\n",
    "    data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "data_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-active",
   "metadata": {},
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()  \n",
    "data_path = os.path.join(folder_path, data_file_name)\n",
    "dataset = load_dataset(data_path)\n",
    "print(f'{time.time() - time_start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_max_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-tuesday",
   "metadata": {},
   "source": [
    "## 3. Fit Gaussian Processes<a name=\"gps\"></a>\n",
    "\n",
    "### 3.1. Set Path to Save GP Files<a name=\"saveGps\"></a>\n",
    "\n",
    "We can now generate a folder structure to neatly save the files. Otherwise, you can directly write the path to the folder to save the GP files in `saved_gps_path`.\n",
    "\n",
    "**<font color=Orange>A)</font>** Generate the folder structure.\n",
    "\n",
    "**Write** the name of the folder you want in `analysis_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = data_file_name[:-5]\n",
    "analysis_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_analysis_path = folder_path[:-14] + 'analyses'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-monkey",
   "metadata": {},
   "source": [
    "Create the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder_structure(folder_analysis_path, analysis_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-camcorder",
   "metadata": {},
   "source": [
    "See the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = get_directories(folder_analysis_path, analysis_name) \n",
    "directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-stationery",
   "metadata": {},
   "source": [
    "Set the path to the folder to save the GP files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_gps = directories['intermediate_files_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-december",
   "metadata": {},
   "source": [
    "**<font color=Orange>B)</font>** Directly choose where to save the GP files.\n",
    "\n",
    "**Write** the path to the folder to save the GP files in `saved_gps_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-qualification",
   "metadata": {},
   "source": [
    "```python\n",
    "saved_gps_path = os.path.join(folder_path, data_file_name[:-5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-anaheim",
   "metadata": {},
   "source": [
    "### 3.2. Compute GP Fits<a name=\"makeGps\"></a>\n",
    "\n",
    "**Choose**:\n",
    "- `t_min`: minimim time to evaluate the Gaussian Process Regression at.\n",
    "- `t_max`: maximum time to evaluate the Gaussian Process Regression at.\n",
    "- `gp_dim`: dimension of the Gaussian Process Regression. If  `gp_dim` is 1, the filters are fitted independently. If `gp_dim` is 2, the Matern kernel is used to fit light curves both in time and wavelength.\n",
    "- `number_gp`: number of points to evaluate the Gaussian Process Regression at.\n",
    "- `number_processes`: number of processors to use for parallelisation (**<font color=green>optional</font>**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_max_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min = 0\n",
    "t_max = 295 # all paper datasets with same range; new wrong procedure\n",
    "\n",
    "gp_dim = 2\n",
    "number_gp = 292 # all paper datasets with same number of points\n",
    "\n",
    "number_processes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps.compute_gps(dataset, number_gp=number_gp, t_min=t_min, t_max=t_max, \n",
    "                gp_dim=gp_dim, output_root=path_saved_gps, \n",
    "                number_processes=number_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_time = time.time()\n",
    "good_objs = []\n",
    "for obj in dataset.object_names:\n",
    "    obj_data = dataset.data[obj]\n",
    "    if np.sum(obj_data['detected']) > 0 and len(obj_data['mjd']) > 1:\n",
    "        good_objs.append(obj)\n",
    "time_taken = time.time() - ini_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good_objs) != len(dataset.object_names):\n",
    "    print('trimming bad events')\n",
    "    ini_time = time.time()\n",
    "    dataset.update_dataset(good_objs)\n",
    "    dataset.update_dataset(list(dataset.metadata.index))\n",
    "    time_taken = time.time() - ini_time\n",
    "    print(time_taken)\n",
    "    \n",
    "    ini_time = time.time()\n",
    "    with open(data_path, 'wb') as f:\n",
    "        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "    time_taken = time.time() - ini_time\n",
    "    print(time_taken)\n",
    "else:\n",
    "    print('good number')\n",
    "    print(len(good_objs))\n",
    "    print(len(dataset.object_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-marble",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 4. Light Curve Visualization<a name=\"see\"></a>\n",
    "\n",
    "Here we show the light curve of an event and the Gaussian process used to fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.object_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WFD\n",
    "#obj_show = '670865' # base train\n",
    "#obj_show = '111116031' # base test 000\n",
    "obj_show = '8580232' # base test 001\n",
    "#obj_show = '93626702' # base test 012\n",
    "\n",
    "#obj_show = '670865' # no roll train ; by coincidence it is the same as baseline\n",
    "#obj_show = '123728213' # no roll test 000\n",
    "\n",
    "#obj_show = '706524' # presto train\n",
    "#obj_show = '27091144' # presto test 000\n",
    "sndata.PlasticcData.plot_obj_and_model(dataset.data[obj_show], \n",
    "                                       dataset.models[obj_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-berry",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
