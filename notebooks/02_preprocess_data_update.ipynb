{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-portugal",
   "metadata": {},
   "source": [
    "# Preprocess Dataset\n",
    "\n",
    "In this notebook we preprocess the the ligh curves such as described in [Link to paper in arXiv](https://arxiv.org/abs/2107.07531).\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load the Original Dataset](#loadData)\n",
    "3. [Preprocess Light Curves](#preprocess)\n",
    "4. [Save Processed PlasticcData](#saveData)\n",
    "5. [Light Curve Comparison](#comparison)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../snmachine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import sndata, analysis\n",
    "from utils.plasticc_pipeline import get_directories, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-transsexual",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-mayor",
   "metadata": {},
   "source": [
    "## 2. Load Original Dataset<a name=\"loadData\"></a>\n",
    "\n",
    "First, **write** the path to the dataset folder `folder_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os_name = 'baseline_v2_0_paper'\n",
    "# os_name = 'noroll_v2_0_paper'\n",
    "os_name = 'presto_v2_0_paper'\n",
    "\n",
    "folder_path = f'/folder/path'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-heating",
   "metadata": {},
   "source": [
    "Then, **write** in `data_file_name` the name of the file where your dataset is saved.\n",
    "\n",
    "In this notebook we use the dataset previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_name_to_save = 'ddf'\n",
    "extra_name_to_save = 'wfd'\n",
    "\n",
    "# name = 'train'\n",
    "name = 'test'\n",
    "\n",
    "# file_id = '000'\n",
    "file_id = '006' # until 012\n",
    "\n",
    "data_file_name = f'{name}_{extra_name_to_save}_{file_id}.pckl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-possible",
   "metadata": {},
   "source": [
    "Load the dataset. It takes 15s and 4min for DDF, respectivelly train and test. It takes ~14-25min for 1/13 WFD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(folder_path, data_file_name)\n",
    "ini_time = time.time()\n",
    "dataset = load_dataset(data_path)\n",
    "print(time.time() - ini_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_max_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.remove_gaps(max_gap_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_max_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collections.Counter(dataset.metadata['target']), len(dataset.metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-sudan",
   "metadata": {},
   "source": [
    "Save the data of one event to later compare on the Section [Light curve transformation](#transformation). **Choose** the event by modifying `obj_show`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.object_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The longest original light curve has {dataset.get_max_length():.2f} days.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDF\n",
    "#obj_show = '416872' # base train\n",
    "#obj_show = '529406' # foot8 train\n",
    "#obj_show = '681000' # base test\n",
    "#obj_show = '209066' # foot8 test\n",
    "\n",
    "# WFD\n",
    "#obj_show = '122420516' # base train\n",
    "#obj_show = '2912729' # base test 000\n",
    "#obj_show = '60282775' # base test 001\n",
    "#obj_show = '34495546' # base test 002\n",
    "###obj_show = '64767080' # base test 003\n",
    "#obj_show = '11702392' # base test 004\n",
    "#obs_before = dataset.data[obj_show].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-marshall",
   "metadata": {},
   "source": [
    "## 3. Preprocess Light Curves<a name=\"preprocess\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_run_everything = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-samuel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_run_everything:\n",
    "    batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "                 '007', '008', '009', '010', '011', '012']\n",
    "    \n",
    "    extra_name_to_save = 'wfd'\n",
    "    \n",
    "    name = 'test'\n",
    "    \n",
    "    max_distance = 50\n",
    "    max_gap_length = 50\n",
    "    \n",
    "    lc_length_s = []\n",
    "    \n",
    "    for i, batch_id in enumerate(batch_ids):\n",
    "        print(f'Batch {batch_id}')\n",
    "    \n",
    "        # Load data\n",
    "        data_file_name = f'{name}_{extra_name_to_save}_{batch_id}.pckl'\n",
    "        data_path = os.path.join(folder_path, data_file_name)\n",
    "        ini_time = time.time()\n",
    "        dataset = load_dataset(data_path)\n",
    "        print(time.time() - ini_time)\n",
    "        print('max', dataset.get_max_length())\n",
    "        \n",
    "        # Select window\n",
    "        if is_only_roll:\n",
    "            ini_time = time.time()\n",
    "            dataset.select_window(window=[60768, None], verbose=True)\n",
    "            time_taken = time.time() - ini_time\n",
    "            print(time_taken)\n",
    "            print('max', dataset.get_max_length())\n",
    "        \n",
    "        # Select transient\n",
    "        ini_time = time.time() # other\n",
    "        dataset.select_transients(max_distance=max_distance, verbose=True)\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "        \n",
    "        # Remove gaps\n",
    "        ini_time = time.time() \n",
    "        dataset.remove_gaps(max_gap_length*2, verbose=True)\n",
    "        dataset.remove_gaps(max_gap_length*2, verbose=True)\n",
    "        dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "        dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "        dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "        \n",
    "        # Keep only events with at least one detection\n",
    "        ini_time = time.time()\n",
    "        good_objs = []\n",
    "        for obj in dataset.object_names:\n",
    "            obj_data = dataset.data[obj]\n",
    "            if np.sum(obj_data['detected']) > 0:\n",
    "                good_objs.append(obj)\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)        \n",
    "        \n",
    "        # Keep only events detected at least 2 days ; I shouls have added this before\n",
    "        ini_time = time.time()\n",
    "        good_objs = []\n",
    "        for obj in dataset.object_names:\n",
    "            obj_data = dataset.data[obj]\n",
    "            if np.max(obj_data['mjd'])-np.min(obj_data['mjd']) > 0.5:\n",
    "                good_objs.append(obj)\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "        \n",
    "        if len(dataset.object_names) != len(good_objs):\n",
    "            print('Something bad unless is 1.5 years datasets')\n",
    "            ini_time = time.time()\n",
    "            dataset.update_dataset(good_objs)\n",
    "            dataset.update_dataset(list(dataset.metadata.index))\n",
    "            time_taken = time.time() - ini_time\n",
    "            print(time_taken)\n",
    "        \n",
    "        # Calculate LC length\n",
    "        ini_time = time.time()\n",
    "        lc_length_s.append(analysis.compute_lc_length(dataset))\n",
    "        print(time.time() - ini_time)\n",
    "        \n",
    "        # Save file\n",
    "        folder_path_to_save = folder_path[:-14]\n",
    "        file_name = data_file_name[:-5]+'_gapless50_updated.pckl'\n",
    "        if is_only_roll:\n",
    "            file_name = data_file_name[:-5]+'_roll_gapless50_updated.pckl'\n",
    "        \n",
    "        ini_time = time.time()\n",
    "        with open(os.path.join(folder_path_to_save, file_name), 'wb') as f:\n",
    "            pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "        \n",
    "        print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-secretary",
   "metadata": {},
   "source": [
    "### 3.1. Only rolling part<a name=\"roll\"></a> <font color=salmon>(Optional)</font>\n",
    "\n",
    "We generated the events between days 60220 and 61325. Since the rolling cadence starts in year 1.5, I will cut all the light curves to be after 60220+548=60768 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_only_roll = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_only_roll:\n",
    "    ini_time = time.time()\n",
    "    dataset.select_window(window=[60768, None], verbose=True)\n",
    "    time_taken = time.time() - ini_time\n",
    "    print(time_taken)\n",
    "    dataset.get_max_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-economy",
   "metadata": {},
   "source": [
    "### 3.2. Select transient part<a name=\"trans\"></a>\n",
    "\n",
    "Select all observations between the detections or within 50 days before the first detection or after the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_time = time.time() # 7min\n",
    "dataset.select_transients(max_distance=max_distance, verbose=True)\n",
    "time_taken = time.time() - ini_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "354+254"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-worse",
   "metadata": {},
   "source": [
    "### 3.3. Remove gaps<a name=\"removeGaps\"></a>\n",
    "\n",
    "**Write** the maximum duration of the gap to allowed in the light curves, `max_gap_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gap_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-correspondence",
   "metadata": {},
   "source": [
    "To remove all the gaps longer than `max_gap_length`, the `remove_gaps` function must be called a few times; it only removes the first gap longer than `max_gap_length`.\n",
    "\n",
    "To introduce uniformity in the dataset, the resulting light curves are translated so their first observation is at time zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-cartoon",
   "metadata": {},
   "source": [
    "This takes ~30min for the WFD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_time = time.time() \n",
    "dataset.remove_gaps(max_gap_length*2, verbose=True)\n",
    "dataset.remove_gaps(max_gap_length*2, verbose=True)\n",
    "dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "#dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "#dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "#dataset.remove_gaps(max_gap_length, verbose=True)\n",
    "time_taken = time.time() - ini_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only events with at least one detection\n",
    "ini_time = time.time()\n",
    "good_objs = []\n",
    "for obj in dataset.object_names:\n",
    "    obj_data = dataset.data[obj]\n",
    "    if (np.sum(obj_data['detected']) > 0) and (np.max(obj_data['mjd'])-np.min(obj_data['mjd'])>.5):\n",
    "        good_objs.append(obj)\n",
    "time_taken = time.time() - ini_time\n",
    "print(time_taken)\n",
    "\n",
    "if len(dataset.object_names) != len(good_objs):\n",
    "    print('Something bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset.object_names) != len(good_objs):\n",
    "    print('Something bad')\n",
    "    ini_time = time.time()\n",
    "    dataset.update_dataset(good_objs)\n",
    "    dataset.update_dataset(list(dataset.metadata.index))\n",
    "    time_taken = time.time() - ini_time\n",
    "    print(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-powder",
   "metadata": {},
   "source": [
    "## 4. Save Processed SnanaData<a name=\"saveData\"></a>\n",
    "\n",
    "Now, **chose** a path to save the SnanaData instance created (`folder_path_to_save`) and the name of the file (`file_name`). It takes ~6-8min to save 1/13 of test set WFD for baseline v2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_to_save = folder_path[:-14]\n",
    "file_name = data_file_name[:-5]+'_gapless50_updated.pckl'\n",
    "if is_only_roll:\n",
    "    file_name = data_file_name[:-5]+'_roll_gapless50_updated.pckl'\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_time = time.time()\n",
    "with open(os.path.join(folder_path_to_save, file_name), 'wb') as f:\n",
    "    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "time_taken = time.time() - ini_time\n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-merchant",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 5. Light Curve Comparison<a name=\"comparison\"></a>\n",
    "\n",
    "Here we show the difference between one original light curve and the transformed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_after = dataset.data[obj_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "sndata.plot_lc(obs_before)\n",
    "plt.axvspan(xmin=729, xmax=849, color='gray', alpha=.3)\n",
    "plt.title('Before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "sndata.plot_lc(obs_after, False)\n",
    "plt.title('After')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-community",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
