{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indoor-section",
   "metadata": {},
   "source": [
    "# Train a Classifier\n",
    "\n",
    "In this notebook we train a Gradient Boosting Decision Tree (GBDT) classifier using the implementation of the package [LightGBM](https://lightgbm.readthedocs.io/en/latest/).\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load Features](#loadFeatures)\n",
    "3. [Generate Classifier](#generateClassifier)\n",
    "    1. [Untrained Classifier](#createClassifier)\n",
    "    2. [Train Classifier](#trainClassifier)\n",
    "    3. [Save the Classifier Instance](#saveClassifier)\n",
    "4. [Performance](#performance) <font color=salmon>(Optional)</font>\n",
    "    1. [Classify Train Set](#classify)\n",
    "    2. [Metrics](#metrics)\n",
    "    3. [Confusion Matrix](#cm)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../snmachine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import snclassifier\n",
    "from utils.plasticc_pipeline import get_directories, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('always', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-alexandria",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-regulation",
   "metadata": {},
   "source": [
    "## 2. Load Features<a name=\"loadFeatures\"></a>\n",
    "\n",
    "First, **write** the path to the folder that contains the features and the labels of the events (`path_saved_features`). These quantities were calculated and saved in [5_feature_extraction](5_feature_extraction.ipynb).\n",
    "\n",
    "### 2.1. Features Path<a name=\"pathFeatures\"></a>\n",
    "\n",
    "**<font color=Orange>A)</font>** Obtain path from folder structure.\n",
    "\n",
    "If you created a folder structure, you can obtain the path from there. **Write** the name of the folder in `analysis_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_only_roll = 0\n",
    "is_updated = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'aug_wfd_46k'\n",
    "if is_only_roll:\n",
    "    analysis_name = 'aug_wfd_roll_46k'\n",
    "if is_updated:\n",
    "    analysis_name = analysis_name + '_updated'\n",
    "analysis_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os_name = 'baseline_v2_0_paper'\n",
    "# os_name = 'noroll_v2_0_paper'\n",
    "os_name = 'presto_v2_0_paper'\n",
    "\n",
    "folder_path = f'/path/folder/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = get_directories(folder_path, analysis_name) \n",
    "path_saved_features = directories['features_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-plenty",
   "metadata": {},
   "source": [
    "**<font color=Orange>B)</font>** Directly **write** where you saved the files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-volume",
   "metadata": {},
   "source": [
    "```python\n",
    "folder_path = '../snmachine/example_data'\n",
    "path_saved_features = folder_path\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-violation",
   "metadata": {},
   "source": [
    "### 2.2. Load<a name=\"load\"></a>\n",
    "\n",
    "Then, load the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(os.path.join(path_saved_features, 'features.pckl'))  # features\n",
    "y = pd.read_pickle(os.path.join(path_saved_features, 'data_labels.pckl'))  # class label of each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-teach",
   "metadata": {},
   "source": [
    "**<font color=Orange>A)</font>** If the dataset is not augmented, skip **<font color=Orange>B)</font>**.\n",
    "\n",
    "\n",
    "**<font color=Orange>B)</font>** If the dataset is augmented, load the augmented dataset.\n",
    "\n",
    "In order to avoid information leaks during the classifier optimization, all synthetic events generated by the training set augmentation which derived from the same original event must be placed in the same cross-validation fold. \n",
    "\n",
    "First, **write** in `data_file_name` the name of the file where your dataset is saved.\n",
    "\n",
    "In this notebook we use the dataset saved in [4_augment_data](4_augment_data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = analysis_name + '.pckl'\n",
    "data_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-mediterranean",
   "metadata": {},
   "source": [
    "Then, load the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_data = f'/folder/path/data/augmented_data'\n",
    "data_path = os.path.join(folder_path_data, data_file_name)\n",
    "dataset = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-financing",
   "metadata": {},
   "source": [
    "## 3. Generate Classifier<a name=\"generateClassifier\"></a>\n",
    "\n",
    "### 3.1. Untrained Classifier<a name=\"createClassifier\"></a>\n",
    "\n",
    "Start by creating a classifier. For that **choose**: \n",
    "\n",
    "- classifier type: `snmachine` contains the following classifiers\n",
    "    * [LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html?highlight=classifier) classifier - `snclassifier.LightGBMClassifier`\n",
    "    * Boosted decision trees - `snclassifier.BoostDTClassifier`\n",
    "    * Boosted random forests - `snclassifier.BoostRFClassifier`\n",
    "    * K-nearest neighbors vote - `snclassifier.KNNClassifier`\n",
    "    * Support vector machine - `snclassifier.SVMClassifier`\n",
    "    * Multi-layer Perceptron classifier of a Neural Network - `snclassifier.NNClassifier`\n",
    "    * Random forest - `snclassifier.RFClassifier`\n",
    "    * Decision tree - `snclassifier.DTClassifier`\n",
    "    * Gaussian Naive Bayes - `snclassifier.NBClassifier`\n",
    "- `random_seed`: this allows reproducible results (**<font color=green>optional</font>**).\n",
    "- `classifier_name`: name under which the classifier is saved (**<font color=green>optional</font>**).\n",
    "- `**kwargs`: optional keywords to pass arguments into the underlying classifier; see the docstring in each classifier for more information (**<font color=green>optional</font>**).\n",
    "\n",
    "Here we chose a LightGBM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'full_opt'\n",
    "classifier_instance = snclassifier.LightGBMClassifier(classifier_name=classifier_name, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-instruction",
   "metadata": {},
   "source": [
    "### 3.2. Train Classifier<a name=\"trainClassifier\"></a>\n",
    "\n",
    "We can now train and use the classifier generated above or optimise it beforehand. In general, it is important to optimise the classifier hyperparameters.\n",
    "\n",
    "If you do not want to optimise the classifier, **run** **<font color=Orange>A)</font>**.\n",
    "\n",
    "**<font color=Orange>A)</font>** Train unoptimised classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-qatar",
   "metadata": {},
   "source": [
    "```python\n",
    "classifier.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-mountain",
   "metadata": {},
   "source": [
    "If you want to optimise the classifier, run **<font color=Orange>B)</font>**.\n",
    "\n",
    "**<font color=Orange>B)</font>** Optimise and train classifier.\n",
    "\n",
    "For that, **choose**:\n",
    "- `param_grid`: parameter grid containing the hyperparameters names and lists of their possible settings as values. If none is provided, the code uses a default parameter grid. (**<font color=green>optional</font>**)\n",
    "- `scoring`: metric used to evaluate the predictions on the validation sets and write it in `scoring`. \n",
    "    * `snmachine` contains the `'auc'` and the PLAsTiCC `'logloss'` costum metrics. For more details about these, see `snclassifier.logloss_score` and `snclassifier.auc_score`, respectively.\n",
    "    * Additionally, you can choose a different metric from the list in [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) or create your own (see [`sklearn.model_selection._search.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for details).\n",
    "- `number_cv_folds`: number of folds for cross-validation. By default it is 5. (**<font color=green>optional</font>**)\n",
    "- `metadata`: metadata of the events with which to train the classifier. This ensures all synthetic events generated by the training set augmentation that were derived from the same original event are placed in the same cross-validation fold. (**<font color=green>optional</font>**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'num_leaves': [10, 30]}\n",
    "\n",
    "classifier_instance.optimise(X, y.astype(str), param_grid=param_grid, scoring='logloss', \n",
    "                             number_cv_folds=5, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_time = time.time()\n",
    "classifier_instance.optimise(X, y.astype(str), param_grid=None, scoring='logloss', \n",
    "                             number_cv_folds=5, metadata=metadata)\n",
    "print(time.time()-ini_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-murray",
   "metadata": {},
   "source": [
    "The classifier is optimised and its optimised hyperparameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance.grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance.classifier_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-attention",
   "metadata": {},
   "source": [
    "### 3.3. Save the Classifier Instance<a name=\"saveClassifier\"></a>\n",
    "\n",
    "**Write** in `path_saved_classifier` the path to the folder where to save the trained classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_classifier = directories['classifications_directory']\n",
    "path_saved_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-lunch",
   "metadata": {},
   "source": [
    "Save the classifier instance (which includes the grid search used to optimise the classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_instance.save_classifier(path_saved_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-mistake",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 4. Performance<a name=\"performance\"></a> <font color=salmon>(Optional)</font>\n",
    "\n",
    "Here we see the training set performance.\n",
    "\n",
    "First, obtain the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = 'full_opt.pck'\n",
    "with open(os.path.join(path_saved_classifier, classifier_name), 'rb') as input:\n",
    "    classifier_instance = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier_instance.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-polymer",
   "metadata": {},
   "source": [
    "### 4.1. Classify Train Set<a name=\"classify\"></a>\n",
    "\n",
    "Compute the predicted class (`y_pred`) and the probability of belonging to each different class (`y_probs`). Note that the predicted class is the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X)\n",
    "y_probs_train = classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-evening",
   "metadata": {},
   "source": [
    "### 4.2. Metrics<a name=\"metrics\"></a>\n",
    "\n",
    "We start by computing the Area under the ROC Curve (AUC) and the PLAsTiCC logloss. For that, choose which class to consider as *positive* (the other classes will be considered *negative*). Then, **write** in `which_column` the column that corresponds to that class. Note that the class order is accessed through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier._classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_column = 2  # we are interested in SN Ia vs others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-valuable",
   "metadata": {},
   "source": [
    "Obtain the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.which_column = which_column\n",
    "auc_test = snclassifier.auc_score(classifier=classifier, X_features=X, \n",
    "                                  y_true=y.astype(str), which_column=which_column)\n",
    "logloss_test = snclassifier.logloss_score(classifier=classifier, X_features=X, \n",
    "                                          y_true=y.astype(str))\n",
    "print('{:^10} {:^10} {:^10}'.format('', 'AUC', 'Logloss'))\n",
    "print('{:^10} {:^10.3f} {:^10.3f}'.format('test', auc_test, logloss_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-moisture",
   "metadata": {},
   "source": [
    "Check how many events we correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_right = y_pred_train == y.astype(str)\n",
    "np.sum(is_pred_right), np.sum(is_pred_right)/len(is_pred_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-petroleum",
   "metadata": {},
   "source": [
    "### 4.3. Confusion Matrix<a name=\"cm\"></a>\n",
    "\n",
    "Now, plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dict_label_to_real_plasticc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Confusion matrix Accuracy'\n",
    "analysis.plot_confusion_matrix(y.astype(str), y_pred_train, \n",
    "                               normalise='accuracy', title=title,\n",
    "                               dict_label_to_real=analysis.dict_label_to_real_plasticc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Confusion matrix Precision'\n",
    "analysis.plot_confusion_matrix(y.astype(str), y_pred_train, \n",
    "                               normalise='precision', title=title,\n",
    "                               dict_label_to_real=analysis.dict_label_to_real_plasticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-macedonia",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
