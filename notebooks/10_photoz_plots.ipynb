{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wooden-characteristic",
   "metadata": {},
   "source": [
    "# Make photoz plots\n",
    "\n",
    "In this notebook we make photo-z plots that include the training set, augmented training set, and test set.\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load Dataset](#loadData)\n",
    "    1. [Load train dataset](#loadTrain)\n",
    "    2. [Load augmented train metadata](#loadAug)\n",
    "    3. [Load test metadata](#loadTest)\n",
    "3. [Plot photo-z distribution](#plot)\n",
    "    1. [Setup](#setup)\n",
    "    3. [Photo-z distribution](#photoz)\n",
    "4. [Number of events](#nEvents)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import snaugment, sndata\n",
    "from utils.plasticc_pipeline import get_directories, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-content",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "size_default = 1.5\n",
    "size_larger = 1.9\n",
    "sns.set(font_scale=size_default, style=\"ticks\", context=\"paper\")\n",
    "sns.set(font_scale=size_default, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-scoop",
   "metadata": {},
   "source": [
    "## 2. Load Dataset<a name=\"loadData\"></a>\n",
    "\n",
    "First, **write** the path to the folder that contains the dataset we want to augment, `folder_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os_name = 'baseline_v2_0_paper'\n",
    "# os_name = 'noroll_v2_0_paper'\n",
    "os_name = 'presto_v2_0_paper'\n",
    "\n",
    "folder_path = f'/folder/path/'\n",
    "folder_analysis_path = folder_path[:-14] + 'analyses'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-jurisdiction",
   "metadata": {},
   "source": [
    "**Set** `is_only_roll` to $1$ to consider only the rolling part of the cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_only_roll = 0\n",
    "is_updated = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-restaurant",
   "metadata": {},
   "source": [
    "### 2.1. Load train dataset<a name=\"loadTrain\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_name_to_save = 'ddf_wfd'\n",
    "\n",
    "file_id = '000'\n",
    "\n",
    "data_file_name = f'train_{extra_name_to_save}_{file_id}_gapless50.pckl'\n",
    "if is_only_roll:\n",
    "    print('only roll')\n",
    "    data_file_name = f'train_{extra_name_to_save}_{file_id}_roll_gapless50.pckl'\n",
    "if is_updated:\n",
    "    data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "data_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(folder_path, data_file_name)\n",
    "train_data = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = train_data.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-yield",
   "metadata": {},
   "source": [
    "### 2.2. Load augmented train metadata<a name=\"loadAug\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'aug_wfd_46k'\n",
    "if is_only_roll:\n",
    "    print('only roll')\n",
    "    analysis_name = 'aug_wfd_roll_46k'\n",
    "if is_updated:\n",
    "    analysis_name = analysis_name + '_updated'\n",
    "    \n",
    "path_saved_photoz = os.path.join(folder_analysis_path, analysis_name, 'wavelet_features')\n",
    "path_saved_plots = os.path.join(folder_analysis_path, analysis_name, 'plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_saved_photoz, 'features.pckl'), 'rb') as input:\n",
    "    metadata_aug = pickle.load(input)  # this is not really the metadata\n",
    "with open(os.path.join(path_saved_photoz, 'data_labels.pckl'), 'rb') as input:\n",
    "    data_labels = pickle.load(input)  # load the class labels\n",
    "metadata_aug['target'] = data_labels  # add the labels to the \"metadata\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-timeline",
   "metadata": {},
   "source": [
    "### 2.2. Load test metadata<a name=\"loadTest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-injury",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_ini = time.time()\n",
    "extra_name_to_save = 'wfd'\n",
    "\n",
    "batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "             '007', '008', '009', '010', '011', '012']\n",
    "\n",
    "# Collect the aggregated data\n",
    "metadata_test_ids = []\n",
    "\n",
    "for batch_id in batch_ids:\n",
    "    print(f'Batch {batch_id}')\n",
    "\n",
    "    # Name and path of the test subset\n",
    "    data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "    if is_only_roll:\n",
    "        print('only roll')\n",
    "        data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "    if is_updated:\n",
    "        data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "    data_path = os.path.join(folder_path, data_file_name)\n",
    "    print(data_path)\n",
    "\n",
    "    # Path to the test subset features\n",
    "    analysis_name = data_file_name[:-5]\n",
    "    folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "    directories = get_directories(folder_analysis_path, analysis_name) \n",
    "    path_saved_reduced_wavelets = directories['features_directory']\n",
    "\n",
    "    # Load the extended metadata\n",
    "    with open(os.path.join(path_saved_reduced_wavelets, 'extended_metadata.pckl'), 'rb') as input:\n",
    "        extended_metadata = pickle.load(input)\n",
    "\n",
    "    # Aggregate the data\n",
    "    metadata_test_ids.append(extended_metadata)\n",
    "metadata_test = pd.concat(metadata_test_ids)\n",
    "print(time.time()-time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-studio",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 3. Plot photo-z distribution<a name=\"plot\"></a>\n",
    "\n",
    "### 3.0. Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "diverg_color = sns.color_palette(\"Set2\", 6, desat=1)\n",
    "sn_type_color = {42: diverg_color[1], 62: diverg_color[0], 90: diverg_color[2], \n",
    "                 52: diverg_color[3], 67: diverg_color[4], 95: diverg_color[5]}\n",
    "sn_type_name = {42: 'SN II', 62: 'SN Ibc', 90: 'SN Ia', \n",
    "                52: 'SN Iax', 67: 'SN 91bg', 95: 'SLSN'}\n",
    "unique_types = [90, 42, 62] #, 52, 67, 95]\n",
    "datasets_ls = ['-', '-', '--']\n",
    "datasets_linewidth = [1, 3, 3]\n",
    "datasets_bw_adjust = [.3, .4, .4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_metadata = [metadata_train, metadata_aug, metadata_test]\n",
    "datasets_label = ['Train. set', 'Aug. set', 'Test set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_name_save = os_name[:-11]\n",
    "if os_name[:-11] == 'baseline' and is_only_roll:\n",
    "    os_name_save = os_name[:-11]+'_onlyroll'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-twist",
   "metadata": {},
   "source": [
    "### 3.1. Photo-z distribution<a name=\"photoz\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sn_type in unique_types: # sns scale 2\n",
    "    plt.figure()\n",
    "    for i, metadata in enumerate(datasets_metadata):\n",
    "        label = datasets_label[i]\n",
    "        ls = datasets_ls[i]\n",
    "        linewidth = datasets_linewidth[i]\n",
    "        bw_adjust= datasets_bw_adjust[i]\n",
    "        is_sn_type = (metadata['target'] == sn_type)\n",
    "        sn_type_metadata = metadata[is_sn_type]\n",
    "        try:\n",
    "            sns.kdeplot(data=sn_type_metadata['hostgal_photoz'],\n",
    "                        label=label, color=sn_type_color[sn_type],\n",
    "                        linestyle=ls, linewidth=linewidth, \n",
    "                        bw_adjust=bw_adjust, clip=(0,None))\n",
    "        except (ValueError, NameError):  # outdated version of matplotlib\n",
    "            sns.distplot(a=sn_type_metadata['hostgal_photoz'], \n",
    "                         label=label, color=sn_type_color[sn_type],\n",
    "                         kde_kws={'linestyle': ls, \n",
    "                                  'linewidth': linewidth, \n",
    "                                  'bw_adjust': bw_adjust})\n",
    "    sn_name = sn_type_name[sn_type]\n",
    "    plt.title(sn_name)\n",
    "    plt.xlim(-.1, 1.2)\n",
    "    plt.ylim(0, 3.)\n",
    "    plt.ylim(0, 3.6)\n",
    "#     if sn_name == 'SN Ibc':\n",
    "#         plt.ylim(0, 3.6)\n",
    "    plt.xlabel('Photometric redshift')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(handletextpad=.3) \n",
    "    \n",
    "    sn_name_save = sn_name.replace(' ', '').lower()\n",
    "    print(os.path.join(path_saved_plots, f'photoz_{os_name_save}_{sn_name_save}_36.pdf'))\n",
    "#     plt.savefig(os.path.join(path_saved_plots, f'photoz_{os_name_save}_{sn_name_save}_36.pdf'), \n",
    "#                 bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-housing",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 4. Number of events<a name=\"nEvents\"></a>\n",
    "\n",
    "Here we check the number of events and proportions per dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_type_name = {42: 'SN II', 62: 'SN Ibc', 90: 'SN Ia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, metadata in enumerate(datasets_metadata):\n",
    "    label = datasets_label[i]\n",
    "    print(label)\n",
    "    counts = collections.Counter(metadata['target'])\n",
    "    for key in counts.keys():\n",
    "        print(sn_type_name[key], counts[key]/len(metadata['target']), counts[key])\n",
    "    print(len(metadata['target']))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-accused",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
