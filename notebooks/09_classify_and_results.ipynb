{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sublime-elephant",
   "metadata": {},
   "source": [
    "# Classify the entire Test Set and obtain results\n",
    "\n",
    "In this notebook we used the previously trained Gradient Boosting Decision Tree (see notebook [6_train_classifier](6_train_classifier.ipynb) for how to train it) to classify the test set. Additionally, we show some performance metrics.\n",
    "\n",
    "In this notebook we also provide some analysis result plots (e.g. recall and precision as a function of the light curve length).\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Test Set Features](#testFeatures)\n",
    "    1. [Compute Features](#computeTestFeatures)\n",
    "    2. [Load Features](#loadTestFeatures)\n",
    "3. [Load Classifier](#loadClassifier)\n",
    "4. [Classify Test Set](#testClassify)\n",
    "5. [Performance](#performance)\n",
    "    1. [Metrics](#metrics)\n",
    "    2. [Confusion Matrix](#cm)\n",
    "    3. [ROC Curves](#roc)\n",
    "6. [Recall and Precision](#precisionRecall)\n",
    "    1. [Load test sets](#loadTest)\n",
    "    1. [Light curve length](#lcLength)\n",
    "        1. [Calculate results](#lcLengthCalc)\n",
    "        2. [Setup](#lcLengthSetup)\n",
    "        3. [Recall](#lcLengthRecall) / [Precision](#lcLengthPrecision) / [Density](#lcLengthDensity)\n",
    "    2. [Median inter-night gap](#medianGap)\n",
    "        1. [Calculate results](#medianGapCalc)\n",
    "        2. [Setup](#medianGapSetup)\n",
    "        3. [Recall](#medianGapRecall) / [Precision](#medianGapPrecision) / [Density](#medianGapDensity)\n",
    "    3. [Longest gap](#maxGap)\n",
    "        1. [Calculate results](#maxGapCalc)\n",
    "        2. [Setup](#maxGapSetup)\n",
    "        3. [Recall](#maxGapRecall) / [Precision](#maxGapPrecision) / [Density](#maxGapDensity)\n",
    "    4. [Number of gaps $\\geq$ 10 days](#numberLargeGap)\n",
    "        1. [Setup](#numberLargeGapSetup)\n",
    "        2. [Recall](#numberLargeGapRecall) / [Precision](#numberLargeGapPrecision) / [Density](#numberLargeGapDensity)\n",
    "    2. [Number of obs in [-10, 30] obs-frame performance](#nearPeak)\n",
    "        1. [Calculate results](#nearPeakCalc)\n",
    "        2. [Setup](#nearPeakSetup)\n",
    "        3. [Recall](#nearPeakRecall) / [Precision](#nearPeakPrecision) / [Density](#nearPeakDensity)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../snmachine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import snclassifier, gps, snfeatures, analysis\n",
    "from utils.plasticc_pipeline import create_folder_structure, get_directories, load_dataset\n",
    "from utils.plasticc_utils import plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-enlargement",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False  # enable autocomplete\n",
    "\n",
    "size_default = 1.5\n",
    "size_larger = 1.9\n",
    "sns.set(font_scale=size_default, style=\"ticks\", context=\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-horizontal",
   "metadata": {},
   "source": [
    "## 2. Test Set Classification Features<a name=\"testFeatures\"></a>\n",
    "\n",
    "Before classifying the test set events, we need to obtain their features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_features = 1  # has calculated features\n",
    "save_features = 0\n",
    "save_updated_metadata = 0\n",
    "is_only_roll = 1\n",
    "is_updated = 1\n",
    "\n",
    "is_show_good = 1  # only show bins with > threshold objs\n",
    "threshold = 300  # 300 = 0.01% of the 3-years baseline test set\n",
    "if is_show_good:\n",
    "    threshold = threshold\n",
    "else:\n",
    "    threshold = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-killing",
   "metadata": {},
   "source": [
    "### 2.1. Compute Features<a name=\"computeTestFeatures\"></a>\n",
    "\n",
    "If the test set features were never calculated, compute them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_name = 'baseline_v2_0_paper'\n",
    "# os_name = 'noroll_v2_0_paper'\n",
    "# os_name = 'presto_v2_0_paper'\n",
    "\n",
    "# dataset_name = '3-years baseline'\n",
    "dataset_name = '1.5-years baseline'\n",
    "\n",
    "folder_path = f'/folder/to/path/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_aug_name = 'aug_wfd_46k'\n",
    "if is_only_roll:\n",
    "    folder_aug_name = folder_aug_name[:-3] + 'roll_46k'\n",
    "if is_updated:\n",
    "    folder_aug_name = folder_aug_name + '_updated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-fever",
   "metadata": {},
   "source": [
    "Then, **write** which `batch_ids` to compute the features on, the path with the basis to project the features, and the number of components to keep.\n",
    "\n",
    "~1h45 per batch_id\n",
    "\n",
    "* baseline: 001 to 012: 13h34min; 10 ids : 18h09min\n",
    "* no roll: 001 to 012: 18h16min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_features == 0:\n",
    "    extra_name_to_save = 'wfd'\n",
    "    batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "                 '007', '008', '009', '010', '011', '012']\n",
    "    \n",
    "    # Path were the basis to project was saved; \n",
    "    # this path changes if we want a different train set\n",
    "    folder_aug_name = 'aug_wfd_46k'\n",
    "#     folder_aug_name = 'aug_wfd_46k_v2'\n",
    "    if is_only_roll:\n",
    "        folder_aug_name = folder_aug_name[:-3] + 'roll_46k'\n",
    "    if is_updated:\n",
    "        folder_aug_name = folder_aug_name + '_updated'\n",
    "    \n",
    "    path_saved_eigendecomp = folder_path+f'../../analyses/{folder_aug_name}/wavelet_features'\n",
    "    print(path_saved_eigendecomp)\n",
    "\n",
    "    # Number of reduced wavelet components to keep\n",
    "    number_comps = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-packing",
   "metadata": {},
   "source": [
    "### 2.2. Load Features<a name=\"loadTestFeatures\"></a>\n",
    "\n",
    "Load previously saved test set features. It takes <1min for all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-kelly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if has_features == 1:\n",
    "    time_ini = time.time()\n",
    "    extra_name_to_save = 'wfd'\n",
    "\n",
    "    batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "                 '007', '008', '009', '010', '011', '012']\n",
    "\n",
    "    # Collect the aggregated data\n",
    "    test_data_ids = []\n",
    "    X_test_ids = []  # features\n",
    "    y_test_ids = []  # classes\n",
    "    metadata_test_ids = []\n",
    "\n",
    "    for batch_id in batch_ids:\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Name and path of the test subset\n",
    "        data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "        if is_only_roll:\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "        if is_updated:\n",
    "            data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "        data_path = os.path.join(folder_path, data_file_name)\n",
    "\n",
    "        # Path to the test subset features\n",
    "        analysis_name = data_file_name[:-5]\n",
    "        folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "        directories = get_directories(folder_analysis_path, analysis_name) \n",
    "        path_saved_reduced_wavelets = directories['features_directory']\n",
    "\n",
    "        # Load the features and extended metadata\n",
    "        with open(os.path.join(path_saved_reduced_wavelets, 'features.pckl'), 'rb') as input:\n",
    "            features = pickle.load(input)\n",
    "        with open(os.path.join(path_saved_reduced_wavelets, 'extended_metadata.pckl'), 'rb') as input:\n",
    "            extended_metadata = pickle.load(input)\n",
    "\n",
    "        # Aggregate the data\n",
    "        print(np.shape(features))\n",
    "        print(np.shape(extended_metadata.target.astype(int)))\n",
    "        print('')\n",
    "        X_test_ids.append(features)\n",
    "        y_test_ids.append(extended_metadata.target.astype(int))\n",
    "        metadata_test_ids.append(extended_metadata)\n",
    "    print(time.time()-time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-leone",
   "metadata": {},
   "source": [
    "## 3. Load Classifier<a name=\"loadClassifier\"></a>\n",
    "\n",
    "First, **write** in `path_saved_classifier` the path to the folder that contains the trained classifier instance. Additionally, **write** in `classifier_name` the name under which the classifier was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_classification = 0  # make classification or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path were the classifier was saved; \n",
    "# this path changes if we want a different classifier\n",
    "path_saved_classifier = folder_path+f'../../analyses/{folder_aug_name}/classifications'\n",
    "path_saved_plots = folder_path+f'../../analyses/{folder_aug_name}/plots'\n",
    "print(path_saved_classifier)\n",
    "print(path_saved_plots)\n",
    "    \n",
    "classifier_name = 'full_opt.pck'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-folder",
   "metadata": {},
   "source": [
    "Load classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_saved_classifier, classifier_name), 'rb') as input:\n",
    "    classifier_instance = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-phoenix",
   "metadata": {},
   "source": [
    "Obtain the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier_instance.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-contamination",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 4. Classify Test Set<a name=\"testClassify\"></a>\n",
    "\n",
    "Compute the predicted class (`y_pred`) and the probability of belonging to each different class (`y_probs`). Note that the predicted class is the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_classification:\n",
    "    time_ini = time.time()\n",
    "\n",
    "    y_pred_test_ids = []\n",
    "    y_probs_test_ids = []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Compute the classification results\n",
    "        y_pred_test = classifier.predict(X_test_ids[i])\n",
    "        y_probs_test = classifier.predict_proba(X_test_ids[i])\n",
    "\n",
    "        # Save results to a list\n",
    "        y_pred_test_ids.append(pd.DataFrame(y_pred_test))\n",
    "        y_probs_test_ids.append(pd.DataFrame(y_probs_test))\n",
    "\n",
    "        # Update metadata\n",
    "        metadata = metadata_test_ids[i]\n",
    "        metadata['y_pred'] = y_pred_test\n",
    "        metadata['y_probs_0'] = y_probs_test[:, 0]\n",
    "        metadata['y_probs_1'] = y_probs_test[:, 1]\n",
    "        metadata['y_probs_2'] = y_probs_test[:, 2]\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            print('Save metadata')\n",
    "            # Path to the saved metadata\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "            if is_only_roll:\n",
    "                print('only roll')\n",
    "                data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "            if is_updated:\n",
    "                data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "            analysis_name = data_file_name[:-5]\n",
    "            folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "            directories = get_directories(folder_analysis_path, analysis_name) \n",
    "            path_saved_metadata = directories['features_directory']\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "\n",
    "    print(time.time()-time_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate also the true label and the extended metadata\n",
    "y_test_all = pd.concat(y_test_ids)\n",
    "metadata_test_all = pd.concat(metadata_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_all = metadata_test_all['y_pred']\n",
    "y_probs_test_all = np.array(metadata_test_all[['y_probs_0', 'y_probs_1', 'y_probs_2']])\n",
    "X_test_all = pd.concat(X_test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-lucas",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 5. Overall Performance<a name=\"performance\"></a>\n",
    "\n",
    "If we know the true class label of each event we can calculate the performance of the classifier. Otherwise, our predictions are saved in `y_pred_test` and `y_probs_test`.\n",
    "\n",
    "In this example we know the true class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-merchant",
   "metadata": {},
   "source": [
    "### 5.1. Metrics<a name=\"metrics\"></a>\n",
    "\n",
    "We start by computing the Area under the ROC Curve (AUC) and the PLAsTiCC logloss. For that, choose which class to consider as *positive* (the other classes will be considered *negative*). Then, **write** in `which_column` the column that corresponds to that class. Note that the class order is accessed through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_column = 2 # we are interested in SN Ia vs others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.which_column = which_column\n",
    "auc_test = snclassifier.auc_score(classifier=classifier, X_features=X_test_all, \n",
    "                                  y_true=y_test_all, which_column=which_column)\n",
    "logloss_test = snclassifier.logloss_score(classifier=classifier, X_features=X_test_all, \n",
    "                                          y_true=y_test_all)\n",
    "print('{:^10} {:^10} {:^10}'.format('', 'AUC', 'Logloss'))\n",
    "print('{:^10} {:^10.3f} {:^10.3f}'.format('test', auc_test, logloss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_boot = 300\n",
    "ini_time = time.time()\n",
    "logloss_s = np.zeros(number_boot)\n",
    "number_objs = y_test_all.shape[0]\n",
    "for k in range(number_boot):  # 300 for bootstrapping the values\n",
    "    indexes = np.random.choice(number_objs, size=int(number_objs), \n",
    "                               replace=True)\n",
    "    logloss_test_i = - snclassifier.logloss_score(classifier=classifier, \n",
    "                                                  X_features=X_test_all.iloc[indexes], \n",
    "                                                  y_true=y_test_all.iloc[indexes])\n",
    "    logloss_s[k] = logloss_test_i\n",
    "print(time.time() - ini_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentil_025 = np.percentile(logloss_s, 2.5)\n",
    "percentil_975 = np.percentile(logloss_s, 97.5)\n",
    "boot_data_ci_s = [percentil_025, percentil_975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_data_ci_s  # 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-mexican",
   "metadata": {},
   "source": [
    "Check how many events we correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pred_right = y_pred_test_all == y_test_all.astype(str)\n",
    "np.sum(is_pred_right), np.sum(is_pred_right)/len(is_pred_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-medicine",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 5.2. Confusion Matrix<a name=\"cm\"></a>\n",
    "\n",
    "Now, plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=size_default, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-bandwidth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title = f'Recall\\nLog-loss = {-logloss_test:.3f}'\n",
    "cm = analysis.plot_confusion_matrix(y_test_all.astype(str), y_pred_test_all.astype(str), \n",
    "                                    normalise='accuracy', title=title, figsize=(5,5),\n",
    "                                    dict_label_to_real=analysis.dict_label_to_real_plasticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-soviet",
   "metadata": {},
   "source": [
    "### 5.3. ROC Curves<a name=\"roc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_classifier_roc_curve(y_test_all, y_probs_test_all,\n",
    "                                   dict_label_to_real=analysis.dict_label_to_real_plasticc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=size_default, style=\"ticks\", context=\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-driving",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "## 6. Precision and Recall<a name=\"precisionRecall\"></a>\n",
    "\n",
    "In this section we produce precision and recall plots for diverse quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_results = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-invite",
   "metadata": {},
   "source": [
    "### 6.0. Load test sets<a name=\"loadTest\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results:  # calculating results envolve loading the test sets\n",
    "    batch_ids = ['003'] \n",
    "#     batch_ids = ['001', '002', '003'] \n",
    "#     batch_ids = ['004', '005', '006', '007', '008'] \n",
    "    \n",
    "    time_ini = time.time() # 1h45 per batch_id\n",
    "\n",
    "    # Keep some data during this run for possible debug\n",
    "    test_data_ids = []\n",
    "\n",
    "    for batch_id in batch_ids:\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Name and path of the test subset\n",
    "        data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "        if is_only_roll:\n",
    "            print('only roll')\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "        if is_updated:\n",
    "            data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "        data_path = os.path.join(folder_path, data_file_name)\n",
    "        print(0, data_path)\n",
    "\n",
    "        # Load the test subset\n",
    "        dataset = load_dataset(data_path)\n",
    "        test_data_ids.append(dataset)\n",
    "        print('')\n",
    "    print(time.time()-time_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_true_snia = (y_test_all == 'SN Ia') | (y_test_all == '90') | (y_test_all == 90)\n",
    "is_true_snii = (y_test_all == 'SN II') | (y_test_all == '42') | (y_test_all == 42)\n",
    "is_true_snibc = (y_test_all == 'SN Ibc') | (y_test_all == '62') | (y_test_all == 62)\n",
    "\n",
    "is_pred_snia = (y_pred_test_all == 'SN Ia') | (y_pred_test_all == '90') | (y_pred_test_all == 90)\n",
    "is_pred_snii = (y_pred_test_all == 'SN II') | (y_pred_test_all == '42') | (y_pred_test_all == 42)\n",
    "is_pred_snibc = (y_pred_test_all == 'SN Ibc') | (y_pred_test_all == '62') | (y_pred_test_all == 62)\n",
    "\n",
    "# Use the same class order for the two lists below\n",
    "is_true_type_list = [is_true_snia, is_true_snibc, is_true_snii] \n",
    "is_pred_type_list = [is_pred_snia, is_pred_snibc, is_pred_snii]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-japan",
   "metadata": {},
   "source": [
    "**Write** in `sn_order` an ordered list of the names of the classes. This should correspond to the class order used in `is_true_type_list`. Additionally, you can provide the colours with which to plot the classes results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_order = ['SN Ia', 'SN Ibc', 'SN II']\n",
    "diverg_color = sns.color_palette(\"Set2\", 3, desat=1)\n",
    "sn_colors = [diverg_color[2], diverg_color[0], diverg_color[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-sandwich",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 6.1. Light curve length<a name=\"lcLength\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-telling",
   "metadata": {},
   "source": [
    "#### 6.1.0. Calculate results<a name=\"lcLengthCalc\"></a>\n",
    "\n",
    "For the entire test set, it takes ~2min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results: \n",
    "    time_ini = time.time()\n",
    "#     batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008', '009', '010', '011', '012']\n",
    "\n",
    "    lc_length_ids = []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Compute LC length/duration\n",
    "        lc_length_id = analysis.compute_lc_length(test_data_ids[i])\n",
    "\n",
    "        # Save the results to the lists\n",
    "        lc_length_ids.append(lc_length_id)\n",
    "        metadata_test_ids[i]['lc_length'] = lc_length_id\n",
    "        metadata = metadata_test_ids[i]\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            # Path to the saved metadata\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "            if is_only_roll:\n",
    "                print('only roll')\n",
    "                data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "            if is_updated:\n",
    "                data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "            analysis_name = data_file_name[:-5]\n",
    "            folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "            directories = get_directories(folder_analysis_path, analysis_name) \n",
    "            path_saved_metadata = directories['features_directory']\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "\n",
    "    lc_length_all = np.concatenate(lc_length_ids)\n",
    "    metadata_test_all = pd.concat(metadata_test_ids)\n",
    "    print(time.time() - time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-dictionary",
   "metadata": {},
   "source": [
    "#### 6.1.1. Setup<a name=\"lcLengthSetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_name = 'lc_length'\n",
    "quantity = metadata_test_all[quantity_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-updating",
   "metadata": {},
   "source": [
    "**Choose** bins for the plot and whether or not to plot the values in the middle of the bins. Additionally, to consider only a subset of events, **mask** those events in `extra_subset`. If `extra_subset = True`, all the events are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 300, 61)\n",
    "use_mid_bins = True  # plot using the middle of the bins\n",
    "extra_subset = True  # use all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-treatment",
   "metadata": {},
   "source": [
    "#### 6.1.2. Recall<a name=\"lcLengthRecall\"></a>\n",
    "\n",
    "Compute the recall and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_s, boot_recall_ci, number_in_bin_s = analysis.compute_recall_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_true_type_list=is_true_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-concord",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < 10])\n",
    "\n",
    "x_label = 'Light curve length (days)'\n",
    "x_min, x_max = -.5, 218\n",
    "\n",
    "x_vline1 = 50\n",
    "x_vline2 = 175\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=recall_s, boot_has_something_ci=boot_recall_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.vlines(x=x_vline1, ymin=0, ymax=1., colors='gray', linewidth=3, ls='--')\n",
    "plt.vlines(x=x_vline2, ymin=0, ymax=1., colors='gray', linewidth=3, ls='--')\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4, loc='lower center')\n",
    "plt.title(dataset_name)\n",
    "\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_recall_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-border",
   "metadata": {},
   "source": [
    "#### 6.1.3. Precision<a name=\"lcLengthPrecision\"></a>\n",
    "\n",
    "Compute the precision and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, boot_precision_ci, number_in_bin_s = analysis.compute_precision_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_pred_type_list=is_pred_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < 10])\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=precision_s, boot_has_something_ci=boot_precision_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.vlines(x=x_vline1, ymin=0, ymax=1., colors='gray', linewidth=3, ls='--')\n",
    "plt.vlines(x=x_vline2, ymin=0, ymax=1., colors='gray', linewidth=3, ls='--')\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4, loc='lower center')\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                          f'{quantity_name}_precision_{os_name[:-11]}.pdf'), \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-earthquake",
   "metadata": {},
   "source": [
    "#### 6.1.4. Density<a name=\"lcLengthDensity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = 0\n",
    "show_sne = False\n",
    "\n",
    "if cumulative != 0 :\n",
    "    bins_hist = 10**4\n",
    "    plt.ylabel('1 - CDF')\n",
    "else:\n",
    "    bins_hist = bins\n",
    "    plt.ylabel('Density')\n",
    "if show_sne:\n",
    "    for j in np.arange(len(is_true_type_list)):\n",
    "        sn_type = sn_order[j]\n",
    "        sn_number = sn_name_to_number[sn_type]\n",
    "        plt.hist(quantity[is_true_type_list[j] & extra_subset],\n",
    "                 density=True, histtype='step', bins=bins_hist,\n",
    "                 label=sn_type, color=sn_type_color[sn_number], \n",
    "                 cumulative=cumulative)\n",
    "    plt.legend()\n",
    "else:\n",
    "    try:\n",
    "        x_vals = quantity[extra_subset]\n",
    "        print('Using a subset of the full test set.')\n",
    "    except KeyError:\n",
    "        x_vals = quantity\n",
    "    plt.hist(x_vals,\n",
    "             density=True, histtype='step', bins=bins_hist,\n",
    "             cumulative=cumulative, linewidth=3)\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "#plt.title(title)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                          f'{quantity_name}_density_{os_name[:-11]}.pdf'), \n",
    "#             bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-somalia",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 6.2. Median inter-night gap<a name=\"medianGap\"></a>\n",
    "\n",
    "Added requirement: more than 2 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-reminder",
   "metadata": {},
   "source": [
    "#### 6.2.0. Calculate results<a name=\"medianGapCalc\"></a>\n",
    "\n",
    "For the entire test set, it takes 2h20min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results: \n",
    "    time_ini = time.time()\n",
    "#     batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008', '009', '010', '011', '012']\n",
    "\n",
    "    median_gap_ids = []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Compute LC length/duration\n",
    "        median_gap_id = analysis.compute_median_internight_gap(\n",
    "            test_data_ids[i])\n",
    "\n",
    "        # Save the results to the lists\n",
    "        median_gap_ids.append(median_gap_id)\n",
    "        metadata_test_ids[i]['median_internight_gap'] = median_gap_id\n",
    "        metadata = metadata_test_ids[i]\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            # Path to the saved metadata\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "            if is_only_roll:\n",
    "                print('only roll')\n",
    "                data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "            if is_updated:\n",
    "                data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "            analysis_name = data_file_name[:-5]\n",
    "            folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "            directories = get_directories(folder_analysis_path, analysis_name) \n",
    "            path_saved_metadata = directories['features_directory']\n",
    "            print(path_saved_metadata)\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "\n",
    "    median_gap_all = np.concatenate(median_gap_ids)\n",
    "    metadata_test_all = pd.concat(metadata_test_ids)\n",
    "    print(time.time() - time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-exercise",
   "metadata": {},
   "source": [
    "#### 6.2.1. Setup<a name=\"medianGapSetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_name = 'median_internight_gap'\n",
    "quantity = metadata_test_all[quantity_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-antenna",
   "metadata": {},
   "source": [
    "**Choose** bins for the plot and whether or not to plot the values in the middle of the bins. Additionally, to consider only a subset of events, **mask** those events in `extra_subset`. If `extra_subset = True`, all the events are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_good_lc = (metadata_test_all['lc_length'] > 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.5, 50.5, 52)\n",
    "use_mid_bins = True  # plot using the middle of the bins\n",
    "extra_subset = True  # use all events\n",
    "# extra_subset = is_good_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-status",
   "metadata": {},
   "source": [
    "#### 6.2.2. Recall<a name=\"medianGapRecall\"></a>\n",
    "\n",
    "Compute the recall and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_s, boot_recall_ci, number_in_bin_s = analysis.compute_recall_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_true_type_list=is_true_type_list, \n",
    "    extra_subset=extra_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-recognition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < 10])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < 10])\n",
    "\n",
    "x_label = 'Median inter-night gap (days)'\n",
    "x_min, x_max = 1, 27\n",
    "#x_min, x_max = 1, 7\n",
    "\n",
    "# x_vline1 = 50\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=recall_s, boot_has_something_ci=boot_recall_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "# plt.vlines(x=x_vline1, ymin=0, ymax=1., colors='gray', linewidth=3, ls='--')\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4, loc='lower right')\n",
    "plt.title(dataset_name)\n",
    "\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_recall_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-question",
   "metadata": {},
   "source": [
    "#### 6.2.3. Precision<a name=\"medianGapPrecision\"></a>\n",
    "\n",
    "Compute the precision and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, boot_precision_ci, number_in_bin_s = analysis.compute_precision_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_pred_type_list=is_pred_type_list, \n",
    "    extra_subset=extra_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=precision_s, boot_has_something_ci=boot_precision_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4, loc='lower right')\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_precision_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-works",
   "metadata": {},
   "source": [
    "#### 6.2.4. Density<a name=\"medianGapDensity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-twist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulative = 0\n",
    "show_sne = False\n",
    "\n",
    "if cumulative != 0 :\n",
    "    bins_hist = 10**4\n",
    "    plt.ylabel('1 - CDF')\n",
    "else:\n",
    "    bins_hist = bins\n",
    "    plt.ylabel('Density')\n",
    "if show_sne:\n",
    "    for j in np.arange(len(is_true_type_list)):\n",
    "        sn_type = sn_order[j]\n",
    "        sn_number = sn_name_to_number[sn_type]\n",
    "        plt.hist(quantity[is_true_type_list[j] & extra_subset],\n",
    "                 density=True, histtype='step', bins=bins_hist,\n",
    "                 label=sn_type, color=sn_type_color[sn_number], \n",
    "                 cumulative=cumulative)\n",
    "    plt.legend()\n",
    "else:\n",
    "    try:\n",
    "        x_vals = quantity[extra_subset]\n",
    "        print('Using a subset of the full test set.')\n",
    "    except KeyError:\n",
    "        x_vals = quantity\n",
    "    plt.hist(x_vals,\n",
    "             density=True, histtype='step', bins=bins_hist,\n",
    "             cumulative=cumulative, linewidth=3)\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "#plt.title(title)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_density_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-navigator",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 6.3. Longest gap<a name=\"maxGap\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-thread",
   "metadata": {},
   "source": [
    "#### 6.3.0. Calculate results<a name=\"maxGapCalc\"></a>\n",
    "\n",
    "For the entire test set baseline, it takes 1h36min.\n",
    "For the entire test set no roll, it takes 2h09min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results: \n",
    "    time_ini = time.time()\n",
    "#     batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008', '009', '010', '011', '012']\n",
    "\n",
    "    max_gap_ids, number_big_gap_ids = [], []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Compute LC length/duration\n",
    "        max_gap_id, number_big_gap_id = analysis.compute_max_and_threshold_gaps(\n",
    "            test_data_ids[i], threshold=10)\n",
    "\n",
    "        # Save the results to the lists\n",
    "        max_gap_ids.append(max_gap_id)\n",
    "        metadata_test_ids[i]['max_gap'] = max_gap_id\n",
    "        number_big_gap_ids.append(number_big_gap_id)\n",
    "        metadata_test_ids[i]['number_big_gap_10'] = number_big_gap_id\n",
    "        metadata = metadata_test_ids[i]\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            # Path to the saved metadata\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "            if is_only_roll:\n",
    "                print('only roll')\n",
    "                data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "            if is_updated:\n",
    "                data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "            analysis_name = data_file_name[:-5]\n",
    "            folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "            directories = get_directories(folder_analysis_path, analysis_name) \n",
    "            path_saved_metadata = directories['features_directory']\n",
    "            print(path_saved_metadata)\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "\n",
    "    max_gap_all = np.concatenate(max_gap_ids)\n",
    "    number_big_gap_10_all = np.concatenate(number_big_gap_ids)\n",
    "    metadata_test_all = pd.concat(metadata_test_ids)\n",
    "    print(time.time() - time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-fighter",
   "metadata": {},
   "source": [
    "#### 6.3.1. Setup<a name=\"maxGapSetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_name = 'max_gap'\n",
    "quantity = metadata_test_all[quantity_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(quantity))\n",
    "print(np.max(quantity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-device",
   "metadata": {},
   "source": [
    "**Choose** bins for the plot and whether or not to plot the values in the middle of the bins. Additionally, to consider only a subset of events, **mask** those events in `extra_subset`. If `extra_subset = True`, all the events are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 50, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 50, 51)\n",
    "use_mid_bins = True  # plot using the middle of the bins\n",
    "extra_subset = True  # use all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-arlington",
   "metadata": {},
   "source": [
    "#### 6.3.2. Recall<a name=\"maxGapRecall\"></a>\n",
    "\n",
    "Compute the recall and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_s, boot_recall_ci, number_in_bin_s = analysis.compute_recall_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_true_type_list=is_true_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "x_label = 'Longest inter-night gap (days)'\n",
    "x_min, x_max = 0, 50\n",
    "#x_min, x_max = 1, 7\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=recall_s, boot_has_something_ci=boot_recall_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_recall_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-north",
   "metadata": {},
   "source": [
    "#### 6.3.3. Precision<a name=\"maxGapPrecision\"></a>\n",
    "\n",
    "Compute the precision and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, boot_precision_ci, number_in_bin_s = analysis.compute_precision_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_pred_type_list=is_pred_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=precision_s, boot_has_something_ci=boot_precision_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_precision_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-worse",
   "metadata": {},
   "source": [
    "#### 6.3.4. Density<a name=\"maxGapDensity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-roommate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cumulative = 0\n",
    "show_sne = False\n",
    "\n",
    "if cumulative != 0 :\n",
    "    bins_hist = 10**4\n",
    "    plt.ylabel('1 - CDF')\n",
    "else:\n",
    "    bins_hist = bins\n",
    "    plt.ylabel('Density')\n",
    "if show_sne:\n",
    "    for j in np.arange(len(is_true_type_list)):\n",
    "        sn_type = sn_order[j]\n",
    "        sn_number = sn_name_to_number[sn_type]\n",
    "        plt.hist(quantity[is_true_type_list[j] & extra_subset],\n",
    "                 density=True, histtype='step', bins=bins_hist,\n",
    "                 label=sn_type, color=sn_type_color[sn_number], \n",
    "                 cumulative=cumulative)\n",
    "    plt.legend()\n",
    "else:\n",
    "    try:\n",
    "        x_vals = quantity[extra_subset]\n",
    "        print('Using a subset of the full test set.')\n",
    "    except KeyError:\n",
    "        x_vals = quantity\n",
    "    plt.hist(x_vals,\n",
    "             density=True, histtype='step', bins=bins_hist,\n",
    "             cumulative=cumulative, linewidth=3)\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "#plt.title(title)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_density_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-cloud",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 6.4. Number of gaps $\\geq$ 10 days<a name=\"numberLargeGap\"></a>\n",
    "\n",
    "Number of big gaps ($\\geq$10 days)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-robin",
   "metadata": {},
   "source": [
    "#### 6.4.1. Setup<a name=\"numberLargeGapSetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_name = 'number_big_gap_10'\n",
    "quantity = metadata_test_all[quantity_name]\n",
    "large_gap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(quantity))\n",
    "print(np.max(quantity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-reconstruction",
   "metadata": {},
   "source": [
    "**Choose** bins for the plot and whether or not to plot the values in the middle of the bins. Additionally, to consider only a subset of events, **mask** those events in `extra_subset`. If `extra_subset = True`, all the events are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 13, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 13, 14)\n",
    "use_mid_bins = False  # plot using the middle of the bins\n",
    "extra_subset = True  # use all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-lender",
   "metadata": {},
   "source": [
    "#### 6.4.2. Recall<a name=\"numberLargeGapRecall\"></a>\n",
    "\n",
    "Compute the recall and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_s, boot_recall_ci, number_in_bin_s = analysis.compute_recall_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_true_type_list=is_true_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "x_label = f'Number of gaps with > {large_gap} days'\n",
    "x_min, x_max = 0, 9\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=recall_s, boot_has_something_ci=boot_recall_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_recall_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-roman",
   "metadata": {},
   "source": [
    "#### 6.4.3. Precision<a name=\"numberLargeGapPrecision\"></a>\n",
    "\n",
    "Compute the precision and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, boot_precision_ci, number_in_bin_s = analysis.compute_precision_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_pred_type_list=is_pred_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=precision_s, boot_has_something_ci=boot_precision_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "# plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_precision_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-malaysia",
   "metadata": {},
   "source": [
    "#### 6.4.4. Density<a name=\"numberLargeGapDensity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-interstate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulative = 0\n",
    "show_sne = False\n",
    "\n",
    "if cumulative != 0 :\n",
    "    bins_hist = 10**4\n",
    "    plt.ylabel('1 - CDF')\n",
    "else:\n",
    "    bins_hist = bins\n",
    "    plt.ylabel('Density')\n",
    "if show_sne:\n",
    "    for j in np.arange(len(is_true_type_list)):\n",
    "        sn_type = sn_order[j]\n",
    "        sn_number = sn_name_to_number[sn_type]\n",
    "        plt.hist(quantity[is_true_type_list[j] & extra_subset],\n",
    "                 density=True, histtype='step', bins=bins_hist,\n",
    "                 label=sn_type, color=sn_type_color[sn_number], \n",
    "                 cumulative=cumulative)\n",
    "    plt.legend()\n",
    "else:\n",
    "    try:\n",
    "        x_vals = quantity[extra_subset]\n",
    "        print('Using a subset of the full test set.')\n",
    "    except KeyError:\n",
    "        x_vals = quantity\n",
    "    plt.hist(x_vals,\n",
    "             density=True, histtype='step', bins=bins_hist,\n",
    "             cumulative=cumulative, linewidth=3)\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "#plt.title(title)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_density_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-anniversary",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "### 6.5. Number of obs in [-10, 30] obs-frame performance<a name=\"nearPeak\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-optics",
   "metadata": {},
   "source": [
    "#### 6.5.0. Calculate results<a name=\"nearPeakCalc\"></a>\n",
    "\n",
    "For the entire test set baseline and presto, it takes 15h09min to calculate `t_peak` and 4h29min to calculate the number of observations near the peak.\n",
    "\n",
    "For the entire test set no roll, it takes 41h30min to calculate `t_peak` and 4h29min to calculate the number of observations near the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-geometry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_ids = ['001', '002', '003', '004', '005', '006', \n",
    "             '007', '008']\n",
    "batch_ids = ['004', '005', '006', '007', '008'] \n",
    "\n",
    "for i, batch_id in enumerate(batch_ids):\n",
    "    print(f'Batch {batch_id}')\n",
    "\n",
    "    # Name and path of the test subset\n",
    "    data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "    if is_only_roll:\n",
    "        print('only roll')\n",
    "        data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "    if is_updated:\n",
    "        data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "    data_path = os.path.join(folder_path, data_file_name)\n",
    "    print(0, data_path)\n",
    "    analysis_name = data_file_name[:-5]\n",
    "    folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "    directories = get_directories(folder_analysis_path, analysis_name)\n",
    "    print(1, directories['features_directory'])\n",
    "    \n",
    "    dataset = test_data_ids[i]\n",
    "    \n",
    "    ini_time = time.time()\n",
    "    good_objs = []\n",
    "    for obj in dataset.object_names:\n",
    "        obj_data = dataset.data[obj]\n",
    "        if np.sum(obj_data['detected']) > 0:\n",
    "            good_objs.append(obj)\n",
    "    time_taken = time.time() - ini_time\n",
    "    print(time_taken)\n",
    "    \n",
    "    if len(good_objs) != len(dataset.object_names):\n",
    "        print('trimming bad events')\n",
    "        ini_time = time.time()\n",
    "        dataset.update_dataset(good_objs)\n",
    "        dataset.update_dataset(list(dataset.metadata.index))\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "\n",
    "        ini_time = time.time()\n",
    "        with open(data_path, 'wb') as f:\n",
    "            pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        metadata = metadata_test_ids[i]\n",
    "        metadata = metadata.loc[good_objs]\n",
    "        metadata_test_ids[i] = metadata\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            path_saved_metadata = directories['features_directory']\n",
    "            print(path_saved_metadata)\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "        time_taken = time.time() - ini_time\n",
    "        print(time_taken)\n",
    "    else:\n",
    "        print('good number')\n",
    "        print(len(good_objs))\n",
    "        print(len(dataset.object_names))\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above was done for 1-3; it misses for 4-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results:\n",
    "    time_ini = time.time()  # ~50min per only roll batch id\n",
    "#     batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008', '009', '010', '011', '012']\n",
    "    \n",
    "#     batch_ids = ['001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008']\n",
    "    \n",
    "#     batch_ids = ['001', '002', '003']\n",
    "#     batch_ids = ['004', '005', '006', '007', '008'] \n",
    "\n",
    "    t_peak_ids = []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Path to the saved metadata\n",
    "        data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "        if is_only_roll:\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "        if is_updated:\n",
    "            data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "        analysis_name = data_file_name[:-5]\n",
    "        folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "        directories = get_directories(folder_analysis_path, analysis_name)\n",
    "        path_saved_gps = directories['intermediate_files_directory']\n",
    "\n",
    "        # Compute LC length/duration\n",
    "        t_peak_id = analysis.compute_t_peak(test_data_ids[i], path_saved_gps)\n",
    "\n",
    "        # Save the results to the lists\n",
    "        t_peak_ids.append(t_peak_id)\n",
    "        metadata_test_ids[i]['t_peak'] = t_peak_id\n",
    "        metadata = metadata_test_ids[i]\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            path_saved_metadata = directories['features_directory']\n",
    "            print(path_saved_metadata)\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "\n",
    "    print(time.time() - time_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_results: \n",
    "    time_ini = time.time()  # 4h29min for all 13 ; # 32min for 3 roll only ; 11min per roll batch id\n",
    "#     batch_ids = ['000', '001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008', '009', '010', '011', '012']\n",
    "    \n",
    "#     batch_ids = ['001', '002', '003', '004', '005', '006', \n",
    "#                  '007', '008']\n",
    "#     batch_ids = ['001', '002', '003'] \n",
    "#     batch_ids = ['004', '005', '006', '007', '008'] \n",
    "\n",
    "    number_obs_peak_ids = []\n",
    "    for i in np.arange(len(batch_ids)):\n",
    "        batch_id = batch_ids[i]\n",
    "        print(f'Batch {batch_id}')\n",
    "\n",
    "        # Compute LC length/duration\n",
    "        t_peak_id = metadata_test_ids[i]['t_peak']\n",
    "        number_obs_peak_id = analysis.compute_number_obs_peak(\n",
    "            test_data_ids[i], t_peak_id)\n",
    "\n",
    "        # Save the results to the lists\n",
    "        number_obs_peak_ids.append(number_obs_peak_id)\n",
    "        metadata = pd.concat([metadata_test_ids[i], number_obs_peak_id], axis=1)\n",
    "        metadata_test_ids[i] = metadata\n",
    "\n",
    "        if save_updated_metadata:\n",
    "            # Path to the saved metadata\n",
    "            data_file_name = f'test_{extra_name_to_save}_{batch_id}_gapless50.pckl'\n",
    "            if is_only_roll:\n",
    "                data_file_name = f'test_{extra_name_to_save}_{batch_id}_roll_gapless50.pckl'\n",
    "            if is_updated:\n",
    "                data_file_name = data_file_name[:-5] + '_updated.pckl'\n",
    "            analysis_name = data_file_name[:-5]\n",
    "            folder_analysis_path = folder_path[:-14] + 'analyses'\n",
    "            directories = get_directories(folder_analysis_path, analysis_name) \n",
    "            path_saved_metadata = directories['features_directory']\n",
    "            print(path_saved_metadata)\n",
    "\n",
    "            metadata.to_pickle(os.path.join(path_saved_metadata, 'extended_metadata.pckl'))\n",
    "    metadata_test_all = pd.concat(metadata_test_ids)\n",
    "    print(time.time() - time_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-stanford",
   "metadata": {},
   "source": [
    "#### 6.5.1. Setup<a name=\"nearPeakSetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_name = 'number_near_peak'\n",
    "quantity = metadata_test_all['prepeak_10'] + metadata_test_all['postpeak_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(quantity))\n",
    "print(np.max(quantity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-actor",
   "metadata": {},
   "source": [
    "**Choose** bins for the plot and whether or not to plot the values in the middle of the bins. Additionally, to consider only a subset of events, **mask** those events in `extra_subset`. If `extra_subset = True`, all the events are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 50, 51)\n",
    "use_mid_bins = False  # plot using the middle of the bins\n",
    "extra_subset = True  # use all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-retail",
   "metadata": {},
   "source": [
    "#### 6.5.2. Recall<a name=\"nearPeakRecall\"></a>\n",
    "\n",
    "Compute the recall and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_s, boot_recall_ci, number_in_bin_s = analysis.compute_recall_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_true_type_list=is_true_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "x_label = 'Number of observations near SNe peak'\n",
    "x_min, x_max = 0, 45\n",
    "#x_min, x_max = 0, 22\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=recall_s, boot_has_something_ci=boot_recall_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_recall_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-nashville",
   "metadata": {},
   "source": [
    "#### 6.5.3. Precision<a name=\"nearPeakPrecision\"></a>\n",
    "\n",
    "Compute the precision and bootstrapped confidence intervals. Then, plot the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_s, boot_precision_ci, number_in_bin_s = analysis.compute_precision_values(\n",
    "    quantity=quantity, bins=bins, is_pred_right=is_pred_right, \n",
    "    use_mid_bins=use_mid_bins, is_pred_type_list=is_pred_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mid_bins:\n",
    "    mid_bins = (bins[:-1]+bins[1:])/2\n",
    "    show_bins = mid_bins\n",
    "else:\n",
    "    show_bins = bins\n",
    "print(show_bins[np.array(number_in_bin_s[:, 0]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 1]) < threshold])\n",
    "print(show_bins[np.array(number_in_bin_s[:, 2]) < threshold])\n",
    "\n",
    "analysis.plot_sne_has_something(\n",
    "    something_s=precision_s, boot_has_something_ci=boot_precision_ci,\n",
    "    bins=show_bins, sn_order=sn_order, \n",
    "    **{'colors': sn_colors, 'number_in_bin_s': number_in_bin_s, \n",
    "       'threshold': threshold, 'linestyle': ['-', '--', '-.']})\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(handletextpad=.4, borderaxespad=.3, handlelength=1.5,\n",
    "           labelspacing=.2, borderpad=.3, columnspacing=.4)\n",
    "plt.title(dataset_name)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_precision_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-belgium",
   "metadata": {},
   "source": [
    "#### 6.5.4. Density<a name=\"nearPeakDensity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-precipitation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cumulative = 0\n",
    "show_sne = False\n",
    "\n",
    "if cumulative != 0 :\n",
    "    bins_hist = 10**4\n",
    "    plt.ylabel('1 - CDF')\n",
    "else:\n",
    "    bins_hist = bins\n",
    "    plt.ylabel('Density')\n",
    "if show_sne:\n",
    "    for j in np.arange(len(is_true_type_list)):\n",
    "        sn_type = sn_order[j]\n",
    "        sn_number = sn_name_to_number[sn_type]\n",
    "        plt.hist(quantity[is_true_type_list[j] & extra_subset],\n",
    "                 density=True, histtype='step', bins=bins_hist,\n",
    "                 label=sn_type, color=sn_type_color[sn_number], \n",
    "                 cumulative=cumulative)\n",
    "    plt.legend()\n",
    "else:\n",
    "    try:\n",
    "        x_vals = quantity[extra_subset]\n",
    "        print('Using a subset of the full test set.')\n",
    "    except KeyError:\n",
    "        x_vals = quantity\n",
    "    plt.hist(x_vals,\n",
    "             density=True, histtype='step', bins=bins_hist,\n",
    "             cumulative=cumulative, linewidth=3)\n",
    "plt.xlabel(x_label)\n",
    "plt.xlim(x_min, x_max) \n",
    "#plt.title(title)\n",
    "# plt.savefig(os.path.join(path_saved_plots, \n",
    "#                         f'{quantity_name}_density_{os_name[:-11]}.pdf'), \n",
    "#            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-filter",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
